# üéØ GU√çA DE USO: CACH√â SEM√ÅNTICO CON PostgreSQL + PGVector

## ¬øC√≥mo habilitar la BD?

En `.env/rag_client.env`, descomenta estas l√≠neas:

```bash
POSTGRES_HOST = postgres           # En Docker: "postgres", En local: "localhost"
POSTGRES_PORT = 5432
POSTGRES_DB = sttcast_rag
POSTGRES_USER = rag_user
POSTGRES_PASSWORD = rag_password   # ‚ö†Ô∏è  CAMBIAR EN PRODUCCI√ìN
```

## ¬øQu√© se guarda?

Cada pregunta en `/api/ask` se guarda en BD:
- **query_text**: La pregunta del usuario
- **response_text**: La respuesta del RAG
- **query_embedding**: Vector de embeddings (1536 dimensiones)
- **podcast_name**: Nombre del podcast
- **created_at**: Timestamp

## ¬øC√≥mo acceder a las queries guardadas?

```python
from rag.client.database import db
import asyncio

# Obtener todas las queries de un podcast
queries = asyncio.run(
    db.get_all_queries(podcast_name="Cowboys de Medianoche", limit=10)
)

# Buscar queries similares (a√∫n no implementado en UI)
similar = asyncio.run(
    db.search_similar_queries(
        query_embedding=[0.1, 0.2, ...],  # embedding de la pregunta
        podcast_name="Cowboys de Medianoche",
        similarity_threshold=0.8
    )
)
```

## Pr√≥xima optimizaci√≥n: CACH√â SEM√ÅNTICO

Antes de consultar `context_server`, el flujo ser√°:

```
1. Usuario pregunta: "¬øQu√© dijeron sobre econom√≠a?"
2. Obtener embedding de la pregunta
3. Buscar en BD: ¬øhay preguntas similares (>0.8 similitud)?
4. SI ‚Üí Retornar respuesta en cach√© (‚ö° r√°pido, sin costo)
5. NO ‚Üí Consultar context_server normalmente (‚Üí guardar en BD)
```

## Estructura de la BD

```sql
-- Tabla principal
CREATE TABLE rag_queries (
    id SERIAL PRIMARY KEY,
    query_text TEXT NOT NULL,
    response_text TEXT NOT NULL,
    query_embedding vector(1536),     -- B√∫squeda sem√°ntica
    created_at TIMESTAMP DEFAULT NOW(),
    podcast_name VARCHAR(255)
);

-- √çndices para performance
CREATE INDEX idx_query_embedding_gist ON rag_queries USING gist (query_embedding);
CREATE INDEX idx_podcast_name ON rag_queries(podcast_name);
CREATE INDEX idx_created_at ON rag_queries(created_at DESC);

-- Tabla de auditor√≠a
CREATE TABLE rag_queries_access_log (
    id SERIAL PRIMARY KEY,
    query_id INTEGER REFERENCES rag_queries(id) ON DELETE CASCADE,
    access_time TIMESTAMP DEFAULT NOW(),
    similarity_score FLOAT
);
```

## M√≥dulo database.py - API

```python
# Guardar query
await db.save_query(
    query_text="¬øQu√© pas√≥ con...?",
    response_text="La respuesta fue...",
    query_embedding=[0.1, 0.2, ...],
    podcast_name="Cowboys de Medianoche"
)

# Buscar similares
similar = await db.search_similar_queries(
    query_embedding=[0.1, 0.2, ...],
    podcast_name="Cowboys de Medianoche",
    limit=5,
    similarity_threshold=0.8
)

# Obtener todo
all_queries = await db.get_all_queries(
    podcast_name="Cowboys de Medianoche",
    limit=100,
    offset=0
)

# Registrar acceso (para auditor√≠a)
await db.log_query_access(query_id=123, similarity_score=0.95)

# Limpiar antiguas (>30 d√≠as)
deleted = await db.cleanup_old_queries(days=30)
```

## Troubleshooting

### ‚ùå Error: "asyncpg not installed"
```bash
pip install asyncpg
```

### ‚ùå Error: "POSTGRES_HOST not configured"
App funciona sin BD. Descomenta las variables en `.env/rag_client.env`

### ‚ùå Error: "Connection refused"
- En Docker: ¬øexiste el servicio postgres en docker-compose.yml?
- En local: ¬øest√° corriendo PostgreSQL? `psql -U rag_user -d sttcast_rag`

### ‚ùå Error: "pgvector extension not found"
```bash
# Dentro del contenedor de postgres
psql -U rag_user -d sttcast_rag
CREATE EXTENSION IF NOT EXISTS vector;
```

## Performance

- **Pool size**: 2-10 conexiones (configurable)
- **Query timeout**: 30 segundos (configurable)
- **√çndices**: GiST para b√∫squedas de embeddings (O(log N))
- **Async**: No bloquea el endpoint `/api/ask`

## Seguridad

‚ö†Ô∏è  En producci√≥n:
1. Cambiar `POSTGRES_PASSWORD`
2. Usar secrets management (AWS Secrets, HashiCorp Vault)
3. Configurar SSL para conexiones a BD
4. Limitar acceso a la BD por firewall

## Pr√≥ximas caracter√≠sticas

- [ ] Dashboard de cach√© hit/miss rate
- [ ] API para consultar queries guardadas
- [ ] Limpieza autom√°tica de queries antiguas
- [ ] Exportar queries a CSV/JSON
- [ ] Visualizar similitudes entre queries
- [ ] Estad√≠sticas de coste evitado (queries en cach√©)
