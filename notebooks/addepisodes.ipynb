{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6387b17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../tools\"))\n",
    "from envvars import load_env_vars_from_directory\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import faiss\n",
    "import glob\n",
    "import re\n",
    "import pysrt\n",
    "import requests\n",
    "from urllib.parse import urljoin\n",
    "import hmac\n",
    "import hashlib\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c0dcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add parent directory to path for imports\n",
    "notebook_dir = os.path.dirname(os.path.abspath(\"__file__\")) if \"__file__\" in globals() else os.getcwd()\n",
    "project_root = os.path.abspath(os.path.join(notebook_dir, '..'))\n",
    "sys.path.insert(0, project_root)\n",
    "\n",
    "from tools.logs import logcfg\n",
    "from tools.envvars import load_env_vars_from_directory\n",
    "from api.apihmac import create_auth_headers, serialize_body\n",
    "\n",
    "import logging\n",
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "from srtparser import parse_srt_file\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "from datetime import datetime\n",
    "\n",
    "# Configurar logging\n",
    "logcfg(__file__ if \"__file__\" in globals() else \"addepisodes.ipynb\")\n",
    "\n",
    "# Cargar variables de entorno\n",
    "env_dir = os.path.join(project_root, '.env')\n",
    "load_env_vars_from_directory(directory=env_dir)\n",
    "\n",
    "# Cargar las claves de autenticación\n",
    "context_server_api_key = os.getenv('CONTEXT_SERVER_API_KEY')\n",
    "if not context_server_api_key:\n",
    "    raise ValueError(\"CONTEXT_SERVER_API_KEY environment variable is not set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5244dddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer el calendario de podcasts\n",
    "caldf = pd.read_csv(cal_file, parse_dates=[\"date\"], index_col=\"episode\" )\n",
    "caldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b81daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "workdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f073eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp3files = glob.glob(os.path.join(workdir, f\"{prefix}*mp3\"))\n",
    "for i in range(len(mp3files)):\n",
    "    mp3files[i] = os.path.basename(mp3files[i])[:-4]\n",
    "mp3files[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fc37ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "epnumber_regex = re.compile(rf\"{prefix}([\\d]+).*\")\n",
    "def get_epnumber(epname):\n",
    "    global epnumber_regex\n",
    "    return int(re.search(epnumber_regex, epname).group(1))\n",
    "epnumbers = [get_epnumber(ep) for ep in mp3files]\n",
    "print (f\"Found {len(epnumbers)} episodes in {workdir} with prefix {prefix}\")\n",
    "print (f\"Last 10 epnumbers: {epnumbers[-10:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44989e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "epdf = pd.DataFrame(mp3files, columns=[\"epname\"])\n",
    "epdf[\"epnumber\"] = epdf[\"epname\"].apply(get_epnumber)\n",
    "\n",
    "epdf[\"epdate\"] = epdf[\"epnumber\"].apply(\n",
    "    lambda x: caldf.loc[x][\"date\"] if x in caldf.index else None\n",
    ")\n",
    "epdf.set_index(\"epname\", inplace=True)\n",
    "epdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b1f6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "textpat = re.compile(r'^\\[(?P<speaker>.*)\\]: *(?P<spoken>.*)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72227edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epints = {}\n",
    "for epname in epdf.index:\n",
    "    epsrt = os.path.join(workdir, f\"{epname}_whisper_es.srt\")\n",
    "    if not os.path.exists(epsrt):\n",
    "        print(f\"Warning: SRT file for {epname} does not exist, skipping.\")\n",
    "        continue\n",
    "    epsubs = pysrt.open(epsrt, encoding='utf-8')\n",
    "    epints[epname] = []\n",
    "    for eps in epsubs:\n",
    "        m = re.match(textpat, eps.text)\n",
    "        if m is None:\n",
    "            print (f\"Fallo en parsear {eps.text}\")\n",
    "            continue\n",
    "        speaker = m.group('speaker')\n",
    "        spoken = m.group('spoken')\n",
    "        start = eps.start.ordinal/1_000\n",
    "        end = eps.end.ordinal/1_000\n",
    "        epints[epname].append({'tag': speaker, 'content': spoken, 'start': start, 'end': end})\n",
    "    print(f\"Número de intervenciones en {epname}: {len(epints[epname])}\")       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37abc1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "addsegments_path = \"/addsegments\"\n",
    "addsegments_url = urlparse(context_server_url)._replace(path=addsegments_path).geturl()\n",
    "for epname in epdf.index:\n",
    "    if epname not in epints:\n",
    "        print(f\"Warning: No interventions found for {epname}, skipping.\")\n",
    "        continue\n",
    "    payload = {\n",
    "        \"epname\": epname,\n",
    "        \"epdate\": epdf.loc[epname][\"epdate\"].isoformat(),\n",
    "        \"epfile\": f\"{prefix}{epname}.mp3\",\n",
    "        \"segments\": epints[epname]\n",
    "    }\n",
    "    try:\n",
    "        # Crear headers de autenticación HMAC usando el módulo centralizado\n",
    "        auth_headers = create_auth_headers(\n",
    "            context_server_api_key,\n",
    "            \"POST\",\n",
    "            addsegments_path,\n",
    "            payload,\n",
    "            client_id='addepisodes_notebook'\n",
    "        )\n",
    "        \n",
    "        # ENVIAR EL JSON EXACTO QUE USAMOS PARA LA FIRMA\n",
    "        body_str = serialize_body(payload)\n",
    "        response = requests.post(addsegments_url, data=body_str, headers=auth_headers)\n",
    "        response.raise_for_status()\n",
    "        print(f\"Successfully added embeddings for {epname}\")\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error adding embeddings for {epname}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e0ef68",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94bdd31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
